{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track-to-track comparison of ERA5 and ERA-Interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from common_defs import nyr, datasets, dset_names\n",
    "import mypaths\n",
    "\n",
    "from octant.core import TrackRun, OctantTrack\n",
    "from octant.misc import SUBSETS\n",
    "import octant\n",
    "octant.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = SUBSETS[1:]  # only PMC and IC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare only three runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_names = (\n",
    "    ('era5_run000', 'ERA5, CTRL'),\n",
    "    ('interim_run106', 'ERA-Interim, CTRL'),\n",
    "    ('interim_run100', 'ERA-Interim, LVT')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_runs = dict()\n",
    "for (dset_name, _) in tqdm(dset_names):\n",
    "    TR = TrackRun()\n",
    "    TR.data = OctantTrack.from_mux_df(pd.read_parquet(mypaths.procdir / f'{dset_name}_2008_2017_top10.parquet', engine='pyarrow'))\n",
    "    TR.is_categorised = True\n",
    "    track_runs[dset_name] = TR\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (dset_name, _) in dset_names:\n",
    "    for subset in subsets:\n",
    "        print(dset_name, subset, track_runs[dset_name].size(subset)/9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_kw = dict(method='bs2000', beta=50., return_dist_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dset = track_runs['era5_run000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_of_coincidence = pd.DataFrame(index=[i[0] for i in dset_names if i[0] != 'era5_run000'], columns=subsets)\n",
    "ratio_of_missing_tracks = probability_of_coincidence.copy()\n",
    "\n",
    "for dset_name in tqdm(probability_of_coincidence.index):\n",
    "    for subset in tqdm(probability_of_coincidence.columns):\n",
    "        match_pairs = ref_dset.match_tracks(track_runs[dset_name],\n",
    "                                            subset=subset,\n",
    "                                            **match_kw)\n",
    "\n",
    "        probability_of_coincidence.loc[dset_name, subset] = len(match_pairs)\n",
    "        ratio_of_missing_tracks.loc[dset_name, subset] = (ref_dset.size(subset) - len(match_pairs)) / track_runs[dset_name].size(subset)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_of_coincidence = pd.DataFrame(a / b, index=[i[0] for i in dset_names if i[0] != 'era5_run000'], columns=subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probability_of_coincidence.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset_name in tqdm(probability_of_coincidence.index):\n",
    "    for subset in tqdm(probability_of_coincidence.columns):\n",
    "        ratio_of_missing_tracks.loc[dset_name, subset] = (ref_dset.size(subset) - probability_of_coincidence.loc[dset_name, subset]) / track_runs[dset_name].size(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ratio_of_missing_tracks.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in tqdm(probability_of_coincidence.columns):\n",
    "    print(ref_dset.size(subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All PMCTRACK runs, split into two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNS = dict()\n",
    "# RUNS['vort_thresh'] = dict()\n",
    "# RUNS['diff_params'] = dict()\n",
    "# for dataset in datasets:\n",
    "#     _runs = []\n",
    "#     for run_id_start in [0, 100]:\n",
    "#         with (mypaths.trackresdir / f'{dataset}_{run_id_start:03d}_runs_grid.json').open('r') as f:\n",
    "#             for run_id, run_dict in enumerate(json.load(f), run_id_start):\n",
    "#                 _runs.append( (run_id, run_dict) )\n",
    "\n",
    "#     RUNS['vort_thresh'][dataset] = []\n",
    "#     RUNS['diff_params'][dataset] = []\n",
    "#     for run_id, run_dict in _runs:\n",
    "#         if  len(run_dict) == 0 and run_id < 100:\n",
    "#             RUNS['diff_params'][dataset].append( (run_id, run_dict) )\n",
    "#         if 'zeta_max0' in run_dict or len(run_dict) == 0:\n",
    "#             if  run_id >= 100:\n",
    "#                 if run_dict != {'zeta_max0': 0.0001, 'zeta_min0': 9e-05}:\n",
    "#                     RUNS['vort_thresh'][dataset].append( (run_id, run_dict) )\n",
    "#         else:\n",
    "#             RUNS['diff_params'][dataset].append( (run_id, run_dict) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for run_id, run_dict in RUNS['vort_thresh']['era5']:\n",
    "#     for run_id_2, run_dict_2 in RUNS['vort_thresh']['interim']:\n",
    "#         if run_dict == run_dict_2:\n",
    "#             print(run_id, run_id_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stars_winters = winters[:3]\n",
    "\n",
    "# TR = TrackRun()\n",
    "# for winter in tqdm(stars_winters, desc='winter', leave=False):\n",
    "#     track_res_dir = mypaths.trackresdir / dataset / f'run{run_id:03d}' / winter\n",
    "#     _TR = TrackRun(track_res_dir)\n",
    "#     _TR.categorise(lsm=lsm, **cat_kw)\n",
    "#     TR += _TR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:clim]",
   "language": "python",
   "name": "conda-env-clim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
